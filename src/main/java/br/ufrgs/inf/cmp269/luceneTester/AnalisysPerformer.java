package br.ufrgs.inf.cmp269.luceneTester;

import java.io.IOException;
import java.io.StringReader;
import java.util.Arrays;
import java.util.HashSet;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.core.LowerCaseFilter;
import org.apache.lucene.analysis.core.StopFilter;
import org.apache.lucene.analysis.es.SpanishAnalyzer;
import org.apache.lucene.analysis.es.SpanishLightStemFilter;
import org.apache.lucene.analysis.standard.StandardTokenizer;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.util.AttributeFactory;

/**
 * Performer for analysis on strings.
 *
 * @author cleber
 */
public class AnalisysPerformer {

    private String originalTarget;
    private final HashSet<AnalysisOption> options;

    /**
     * Creates a new analysis performer with analysis options to be performed.
     *
     * @param options Array of options.
     */
    public AnalisysPerformer(AnalysisOption[] options) {
        this.options = new HashSet<>(Arrays.asList(options));
    }

    /**
     * Creates a new analysis performer with analysis options to be performed.
     *
     * @param options Hash set of options.
     */
    public AnalisysPerformer(HashSet<AnalysisOption> options) {
        this.options = options;
    }

    /**
     * Analyzes a string according to the options passed when creating this
     * instance.
     *
     * @param target String to be analyzed.
     * @return The analyzed string.
     */
    public String analyze(String target) {
        this.originalTarget = target;

        if (options.isEmpty()) {
            return target;
        }

        AttributeFactory factory = AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY;
        StandardTokenizer standardTokenizer = new StandardTokenizer(factory);
        standardTokenizer.setReader(new StringReader(originalTarget));
        TokenStream tokenStream = standardTokenizer;

        tokenStream = new LowerCaseFilter(tokenStream);

        if (options.contains(AnalysisOption.STOP_WORDS)) {
            tokenStream = new StopFilter(tokenStream, SpanishAnalyzer.getDefaultStopSet());
        }

        if (options.contains(AnalysisOption.STEM)) {
            tokenStream = new SpanishLightStemFilter(tokenStream);
        }

        return getAnalyzedTarget(tokenStream);
    }

    /**
     * Gets the string generated by then token stream. If this method is called
     * in the same instance twice, it will generate an error.
     *
     * @param tokenStream Source of tokens.
     * @return tokens separated by space in a string.
     */
    private String getAnalyzedTarget(TokenStream tokenStream) {
        String target;
        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);
        try {
            StringBuilder sb = new StringBuilder();

            tokenStream.reset();
            while (tokenStream.incrementToken()) {
                String term = charTermAttribute.toString();
                sb.append(term).append(" ");
            }
            target = sb.toString();
        } catch (IOException exception) {
            target = this.originalTarget;
            System.out.println("[ERROR] Unable to stringfy token stream. Error: " + exception.getMessage());
        }

        return target;
    }
}
